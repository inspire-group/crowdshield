{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import sys\n",
    "PREPROCESS_PATH = '../lib/twitter_preprocess'\n",
    "sys.path.append(PREPROCESS_PATH)\n",
    "from twitter_preprocess import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path_25 = 'glove.twitter.27B/glove.twitter.27B.25d.txt'\n",
    "with open(glove_path_25, 'rb') as lines:\n",
    "    w2v_25 = {line.split()[0]: np.array(map(float, line.split()[1:])) for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path_100 = 'glove.twitter.27B/glove.twitter.27B.100d.txt'\n",
    "with open(glove_path_100, 'rb') as lines:\n",
    "    w2v_100 = {line.split()[0]: np.array(map(float, line.split()[1:])) for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path_200 = 'glove.twitter.27B/glove.twitter.27B.200d.txt'\n",
    "with open(glove_path_200, 'rb') as lines:\n",
    "    w2v_200 = {line.split()[0]: np.array(map(float, line.split()[1:])) for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(object):\n",
    "    \n",
    "    def __init__(self, train_path, test_path, context_path=None, word2vec=None):\n",
    "        pass\n",
    "        \n",
    "    def load_context(self, context_path):\n",
    "        file_path = context_path\n",
    "        delimiter = ';'\n",
    "        reader = csv.reader(open(file_path,\"rb\"),delimiter=delimiter)\n",
    "        texts = []\n",
    "        for row in reader:\n",
    "            text = row[4]\n",
    "            texts.append(text)\n",
    "        context = texts\n",
    "        return context\n",
    "        \n",
    "    def load_data(self, data_path):\n",
    "        file_path = data_path\n",
    "        delimiter = ';'\n",
    "        reader = csv.reader(open(file_path,\"rb\"),delimiter=delimiter)\n",
    "        rows = []\n",
    "        for row in reader:\n",
    "            rows.append(row)\n",
    "        labels  = np.array([int(x[0]) for x in rows])\n",
    "        data  = [x[1] for x in rows]\n",
    "        return data, labels\n",
    "        \n",
    "    def preprocess(self, data):\n",
    "        tweets = data\n",
    "        tokenizer = TweetTokenizer()\n",
    "        preproc_tweets = map(lambda t: tokenize(t), tweets)\n",
    "        preproc_tweets = map(lambda t: tokenizer.tokenize(t), preproc_tweets)\n",
    "        #preproc_tweets = map(lambda t: filter(lambda w: w not in stop_words, t), preproc_tweets)\n",
    "        return preproc_tweets\n",
    "    \n",
    "    def feature_extract(self, preproc_data):\n",
    "        tweets = preproc_data\n",
    "        word2vec = self.word2vec\n",
    "        mean_embeds = np.array([\n",
    "                        np.mean([word2vec[w] for w in words if w in word2vec]\n",
    "                                or [np.zeros(dim)], axis=0)\n",
    "                        for words in tweets\n",
    "                    ])\n",
    "        return mean_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecFeatureExtractor(FeatureExtractor):\n",
    "    def __init__(self, train_path, test_path, context_path, size):\n",
    "        context = self.load_context(context_path)\n",
    "        preproc_context = self.preprocess(context)\n",
    "        model = Word2Vec(preproc_context, size=size)\n",
    "        self.word2vec = dict(zip(model.wv.index2word, model.wv.syn0))\n",
    "        \n",
    "        train, train_labels = self.load_data(train_path)\n",
    "        preproc_train = self.preprocess(train)\n",
    "        self.train_vecs = self.feature_extract(preproc_train)\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        test, test_labels = self.load_data(test_path)\n",
    "        preproc_test = self.preprocess(test)\n",
    "        self.test_vecs = self.feature_extract(preproc_test)\n",
    "        self.test_labels = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloveFeatureExtractor(FeatureExtractor):\n",
    "    def __init__(self, train_path, test_path, context_path, glove):\n",
    "        _ = context_path\n",
    "        self.word2vec = glove\n",
    "        \n",
    "        train, train_labels = self.load_data(train_path)\n",
    "        preproc_train = self.preprocess(train)\n",
    "        self.train_vecs = self.feature_extract(preproc_train)\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        test, test_labels = self.load_data(test_path)\n",
    "        preproc_test = self.preprocess(test)\n",
    "        self.test_vecs = self.feature_extract(preproc_test)\n",
    "        self.test_labels = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "\n",
    "    def fit(self, X):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of\n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(object):\n",
    "    \n",
    "    def __init__(self, fe):\n",
    "        self.train_vecs = fe.train_vecs\n",
    "        self.train_labels = fe.train_labels\n",
    "        self.test_vecs = fe.test_vecs\n",
    "        self.test_labels = fe.test_labels\n",
    "        self.clf = None\n",
    "        \n",
    "    def sample_data(self, sample_size):\n",
    "        if not sample_size:\n",
    "            return\n",
    "        sample_idxs = np.random.choice(self.train_vecs.shape[0], sample_size, False)\n",
    "        self.train_vecs = self.train_vecs[sample_idxs]\n",
    "        self.train_labels = self.train_labels[sample_idxs]\n",
    "    \n",
    "    def fit_predict(self):\n",
    "        train_vecs = self.train_vecs\n",
    "        train_labels = self.train_labels\n",
    "        test_vecs = self.test_vecs\n",
    "        clf = self.clf\n",
    "        clf.fit(train_vecs, train_labels)\n",
    "        self.preds = clf.predict(test_vecs)\n",
    "        \n",
    "    def evaluate(self):\n",
    "        test_labels = self.test_labels\n",
    "        preds = self.preds\n",
    "        assert(len(test_labels)==len(preds)), \"Prediction length differs from test lengths\"\n",
    "        y = test_labels\n",
    "        tp, fp, tn, fn = 0, 0, 0, 0\n",
    "        for i in range(len(preds)):\n",
    "            if preds[i] == 1 and y[i] == 1: tp += 1\n",
    "            elif preds[i] == 1 and y[i] == 0: fp += 1\n",
    "            elif preds[i] == 0 and y[i] == 0: tn += 1\n",
    "            else: fn += 1\n",
    "        precision = tp / float(tp + fp) if (tp + fp) > 0 else float(tp)\n",
    "        recall = tp / float(tp + fn) if (tp + fn) > 0 else float(tp)\n",
    "        f1 = 2 / (1/precision + 1/recall) if precision > 0 and recall > 0 else 0\n",
    "        print \"Precision: {}, Recall: {}, F1: {}\".format(precision, recall, f1)\n",
    "        return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMClassifier(Classifier):\n",
    "    \n",
    "    def __init__(self, fe, C=0.3):\n",
    "        self.train_vecs = fe.train_vecs\n",
    "        self.train_labels = fe.train_labels\n",
    "        self.test_vecs = fe.test_vecs\n",
    "        self.test_labels = fe.test_labels\n",
    "        self.clf = svm.SVC(C=0.3, kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_routine(context_path, train_path, test_path, sample_size=None):\n",
    "    print \"################# GLOVE 25-DIM ##################\"\n",
    "    w2v_25 = w2v\n",
    "    fe = GloveFeatureExtractor(train_path, test_path, None, w2v_25)\n",
    "    clf = SVMClassifier(fe, C=0.3)\n",
    "    clf.sample_data(sample_size)\n",
    "    clf.fit_predict()\n",
    "    clf.evaluate()\n",
    "    print\n",
    "\n",
    "    print \"################# GLOVE 100-DIM ##################\"\n",
    "    fe = GloveFeatureExtractor(train_path, test_path, None, w2v_100)\n",
    "    clf = SVMClassifier(fe, C=0.3)\n",
    "    clf.sample_data(sample_size)\n",
    "    clf.fit_predict()\n",
    "    clf.evaluate()\n",
    "    print\n",
    "\n",
    "    print \"################# GLOVE 200-DIM ##################\"\n",
    "    fe = GloveFeatureExtractor(train_path, test_path, None, w2v_200)\n",
    "    clf = SVMClassifier(fe, C=0.3)\n",
    "    clf.sample_data(sample_size)\n",
    "    clf.fit_predict()\n",
    "    clf.evaluate()\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_routine(context_path, train_path, test_path, sample_size=None, iters=1):\n",
    "    dim25, dim100, dim200 = [], [], []\n",
    "    for i in iters:\n",
    "        #print \"################# W2V 25-DIM ##################\"\n",
    "        fe = Word2VecFeatureExtractor(train_path, test_path, context_path, size=25)\n",
    "        clf = SVMClassifier(fe, C=0.3)\n",
    "        clf.sample_data(sample_size)\n",
    "        clf.fit_predict()\n",
    "        p, r, f1 = clf.evaluate()\n",
    "        dim25.append((p, r, f1))\n",
    "        #print\n",
    "\n",
    "        #print \"################# W2V 100-DIM ##################\"\n",
    "        fe = Word2VecFeatureExtractor(train_path, test_path, context_path, size=100)\n",
    "        clf = SVMClassifier(fe, C=0.3)\n",
    "        clf.sample_data(sample_size)\n",
    "        clf.fit_predict()\n",
    "        p, r, f1 = clf.evaluate()\n",
    "        dim100.append((p, r, f1))\n",
    "        #print\n",
    "\n",
    "        #print \"################# W2V 200-DIM ##################\"\n",
    "        fe = Word2VecFeatureExtractor(train_path, test_path, context_path, size=200)\n",
    "        clf = SVMClassifier(fe, C=0.3)\n",
    "        clf.sample_data(sample_size)\n",
    "        clf.fit_predict()\n",
    "        p, r, f1 = clf.evaluate()\n",
    "        dim200.append((p, r, f1))\n",
    "        #print\n",
    "    return dim25, dim100, dim200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_path = 'data/KaepernickStorm.csv'\n",
    "train_path = 'data/KaepernickTrain.csv'\n",
    "test_path = 'data/KaepernickTest.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# GLOVE 25-DIM ##################\n",
      "Precision: 0.65274151436, Recall: 0.886524822695, F1: 0.751879699248\n",
      "\n",
      "################# GLOVE 100-DIM ##################\n",
      "Precision: 0.778135048232, Recall: 0.858156028369, F1: 0.816188870152\n",
      "\n",
      "################# GLOVE 200-DIM ##################\n",
      "Precision: 0.799342105263, Recall: 0.86170212766, F1: 0.829351535836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glove_routine(context_path, train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# W2V 25-DIM ##################\n",
      "Precision: 0.78892733564, Recall: 0.808510638298, F1: 0.798598949212\n",
      "\n",
      "################# W2V 100-DIM ##################\n",
      "Precision: 0.766990291262, Recall: 0.840425531915, F1: 0.802030456853\n",
      "\n",
      "################# W2V 200-DIM ##################\n",
      "Precision: 0.778145695364, Recall: 0.833333333333, F1: 0.804794520548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec_routine(context_path, train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# GLOVE 25-DIM ##################\n",
      "Precision: 0.564, Recall: 1.0, F1: 0.721227621483\n",
      "\n",
      "################# GLOVE 100-DIM ##################\n",
      "Precision: 0.823529411765, Recall: 0.0496453900709, F1: 0.0936454849498\n",
      "\n",
      "################# GLOVE 200-DIM ##################\n",
      "Precision: 0.564, Recall: 1.0, F1: 0.721227621483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glove_routine(context_path, train_path, test_path, sample_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# W2V 25-DIM ##################\n",
      "Precision: 0.777385159011, Recall: 0.780141843972, F1: 0.778761061947\n",
      "\n",
      "################# W2V 100-DIM ##################\n",
      "Precision: 0.76897689769, Recall: 0.826241134752, F1: 0.796581196581\n",
      "\n",
      "################# W2V 200-DIM ##################\n",
      "Precision: 0.766666666667, Recall: 0.815602836879, F1: 0.790378006873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec_routine(context_path, train_path, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating 100-d Word2Vec Model on UserTrend's Local Month Twitter corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = Word2VecFeatureExtractor(train_path, test_path, context_path)\n",
    "clf = SVMClassifier(fe, C=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.771241830065, Recall: 0.836879432624, F1: 0.802721088435\n"
     ]
    }
   ],
   "source": [
    "clf.fit_predict()\n",
    "clf.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating 25-d Word2Vec Model on UserTrend's Local Month Twitter corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.805653710247, Recall: 0.808510638298, F1: 0.807079646018\n"
     ]
    }
   ],
   "source": [
    "fe = Word2VecFeatureExtractor(train_path, test_path, context_path, size=25)\n",
    "clf = SVMClassifier(fe, C=0.3)\n",
    "clf.fit_predict()\n",
    "clf.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.766666666667, Recall: 0.815602836879, F1: 0.790378006873\n"
     ]
    }
   ],
   "source": [
    "fe = Word2VecFeatureExtractor(train_path, test_path, context_path, size=200)\n",
    "clf = SVMClassifier(fe, C=0.3)\n",
    "clf.fit_predict()\n",
    "clf.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating 25-d GloVe Model on Pre-trained Twitter corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.65274151436, Recall: 0.886524822695, F1: 0.751879699248\n"
     ]
    }
   ],
   "source": [
    "w2v_25 = w2v\n",
    "fe = GloveFeatureExtractor(train_path, test_path, None, w2v_25)\n",
    "clf = SVMClassifier(fe, C=0.3)\n",
    "clf.fit_predict()\n",
    "clf.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating 100-d GloVe Model on Pre-trained Twitter corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.778135048232, Recall: 0.858156028369, F1: 0.816188870152\n"
     ]
    }
   ],
   "source": [
    "fe = GloveFeatureExtractor(train_path, test_path, None, w2v_100)\n",
    "clf = SVMClassifier(fe, C=0.3)\n",
    "clf.fit_predict()\n",
    "clf.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating 100-d GloVe Model on Pre-trained Twitter corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.799342105263, Recall: 0.86170212766, F1: 0.829351535836\n"
     ]
    }
   ],
   "source": [
    "fe = GloveFeatureExtractor(train_path, test_path, None, w2v_200)\n",
    "clf = SVMClassifier(fe, C=0.3)\n",
    "clf.fit_predict()\n",
    "clf.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_path = 'data/MelaniaTrumpStorm.csv'\n",
    "train_path = 'data/MelaniaTrumpTrain.csv'\n",
    "test_path = 'data/MelaniaTrumpTest.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# GLOVE 25-DIM ##################\n",
      "Precision: 0.767441860465, Recall: 0.673469387755, F1: 0.717391304348\n",
      "\n",
      "################# GLOVE 100-DIM ##################\n",
      "Precision: 0.75, Recall: 0.0612244897959, F1: 0.11320754717\n",
      "\n",
      "################# GLOVE 200-DIM ##################\n",
      "Precision: 0.59756097561, Recall: 1.0, F1: 0.748091603053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"################# GLOVE 25-DIM ##################\"\n",
    "w2v_25 = w2v\n",
    "fe = GloveFeatureExtractor(train_path, test_path, None, w2v_25)\n",
    "clf = SVMClassifier(fe, C=0.3)\n",
    "clf.sample_data(30)\n",
    "clf.fit_predict()\n",
    "clf.evaluate()\n",
    "print\n",
    "\n",
    "print \"################# GLOVE 100-DIM ##################\"\n",
    "fe = GloveFeatureExtractor(train_path, test_path, None, w2v_100)\n",
    "clf = SVMClassifier(fe, C=0.3)\n",
    "clf.sample_data(30)\n",
    "clf.fit_predict()\n",
    "clf.evaluate()\n",
    "print\n",
    "\n",
    "print \"################# GLOVE 200-DIM ##################\"\n",
    "fe = GloveFeatureExtractor(train_path, test_path, None, w2v_200)\n",
    "clf = SVMClassifier(fe, C=0.3)\n",
    "clf.sample_data(30)\n",
    "clf.fit_predict()\n",
    "clf.evaluate()\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# W2V 25-DIM ##################\n",
      "Precision: 0.713567839196, Recall: 0.965986394558, F1: 0.820809248555\n",
      "\n",
      "################# W2V 100-DIM ##################\n",
      "Precision: 0.751479289941, Recall: 0.863945578231, F1: 0.803797468354\n",
      "\n",
      "################# W2V 200-DIM ##################\n",
      "Precision: 0.588, Recall: 1.0, F1: 0.740554156171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"################# W2V 25-DIM ##################\"\n",
    "fe = Word2VecFeatureExtractor(train_path, test_path, context_path, size=25)\n",
    "clf = SVMClassifier(fe, C=0.3)\n",
    "clf.sample_data(30)\n",
    "clf.fit_predict()\n",
    "clf.evaluate()\n",
    "print\n",
    "\n",
    "print \"################# W2V 100-DIM ##################\"\n",
    "fe = Word2VecFeatureExtractor(train_path, test_path, context_path, size=100)\n",
    "clf = SVMClassifier(fe, C=0.3)\n",
    "clf.sample_data(30)\n",
    "clf.fit_predict()\n",
    "clf.evaluate()\n",
    "print\n",
    "\n",
    "print \"################# W2V 200-DIM ##################\"\n",
    "fe = Word2VecFeatureExtractor(train_path, test_path, context_path, size=200)\n",
    "clf = SVMClassifier(fe, C=0.3)\n",
    "clf.sample_data(30)\n",
    "clf.fit_predict()\n",
    "clf.evaluate()\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
